```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler # 답변 실시간 생성

chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])
```

# chef_chain
```python
chef_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a world-class international chef. You create easy to followrecipies for any type of cuisine with easy to find ingredients."),
    ("human", "I want to cook {cuisine} food."),
])

chef_chain = chef_prompt | chat
```

# veg_chain
```python
veg_chef_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it."""),
    ("human", "{recipe}")
])

veg_chain = veg_chef_prompt | chat
```

# chef_chain과 veg_chain을 연결해보자 by LCEL
```python
# chain을 따로 동작시킨다고 하면 아래와 같다.
# chef_chain.invoke({"cuisine" : "bread"})
# veg_chain.invoke({"recipe" : "recipe blah blah blah..."})

# chef_chain의 출력값(output)으로 veg_chain 실행
# chef_chain 출력값(output) = veg_chain 입력값(input)
final_chain = {"recipe" : chef_chain} | veg_chain
final_chain.invoke({
    "cuisine" : "indian"
})
```